{
 "metadata": {
  "name": "",
  "signature": "sha256:533719d6c478882615e59527979e8571426af91a603d8fc53a5b08b057f14f19"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Adaboost\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##\uc2e4\ud5d8\ub370\uc774\ud130\n",
      "\n",
      "1. Title: Wisconsin Breast Cancer Database (January 8, 1991)\n",
      "\n",
      "2. Sources:\n",
      "   -- Dr. WIlliam H. Wolberg (physician)\n",
      "      University of Wisconsin Hospitals\n",
      "      Madison, Wisconsin\n",
      "      USA\n",
      "   -- Donor: Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
      "      Received by David W. Aha (aha@cs.jhu.edu)\n",
      "   -- Date: 15 July 1992\n",
      "\n",
      "3. Past Usage:\n",
      "\n",
      "   Attributes 2 through 10 have been used to represent instances.\n",
      "   Each instance has one of 2 possible classes: benign or malignant.\n",
      "\n",
      "   1. Wolberg,~W.~H., \\& Mangasarian,~O.~L. (1990). Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology. In\n",
      "      {\\it Proceedings of the National Academy of Sciences}, {\\it 87},\n",
      "      9193--9196.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Collected classification results: 1 trial only\n",
      "      -- Two pairs of parallel hyperplanes were found to be consistent with\n",
      "         50% of the data\n",
      "         -- Accuracy on remaining 50% of dataset: 93.5%\n",
      "      -- Three pairs of parallel hyperplanes were found to be consistent with\n",
      "         67% of data\n",
      "         -- Accuracy on remaining 33% of dataset: 95.9%\n",
      "\n",
      "   2. Zhang,~J. (1992). Selecting typical instances in instance-based\n",
      "      learning.  In {\\it Proceedings of the Ninth International Machine\n",
      "      Learning Conference} (pp. 470--479).  Aberdeen, Scotland: Morgan\n",
      "      Kaufmann.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Applied 4 instance-based learning algorithms \n",
      "      -- Collected classification results averaged over 10 trials\n",
      "      -- Best accuracy result: \n",
      "         -- 1-nearest neighbor: 93.7%\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "      -- Also of interest:\n",
      "         -- Using only typical instances: 92.2% (storing only 23.1 instances)\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   Samples arrive periodically as Dr. Wolberg reports his clinical cases.\n",
      "   The database therefore reflects this chronological grouping of the data.\n",
      "   This grouping information appears immediately below, having been removed\n",
      "   from the data itself:\n",
      "\n",
      "     Group 1: 367 instances (January 1989)<br>\n",
      "     Group 2:  70 instances (October 1989)<br>\n",
      "     Group 3:  31 instances (February 1990)<br>\n",
      "     Group 4:  17 instances (April 1990)<br>\n",
      "     Group 5:  48 instances (August 1990)<br>\n",
      "     Group 6:  49 instances (Updated January 1991)<br>\n",
      "     Group 7:  31 instances (June 1991)<br>\n",
      "     Group 8:  86 instances (November 1991)<br>\n",
      "     -----------------------------------------<br>\n",
      "     Total:   699 points (as of the donated datbase on 15 July 1992)<br>\n",
      "\n",
      "   Note that the results summarized above in Past Usage refer to a dataset\n",
      "   of size 369, while Group 1 has only 367 instances.  This is because it\n",
      "   originally contained 369 instances; 2 were removed.  The following\n",
      "   statements summarizes changes to the original Group 1's set of data:\n",
      "\n",
      "    #####  Group 1 : 367 points: 200B 167M (January 1989)<br>\n",
      "    #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805<br>\n",
      "    #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record<br>\n",
      "    #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial<br>\n",
      "    #####                  : Changed 0 to 1 in field 6 of sample 1219406 <br>\n",
      "    #####                  : Changed 0 to 1 in field 8 of following sample:<br>\n",
      "    #####                  : 1182404,2,3,1,1,1,2,0,1,1,1<br>\n",
      "\n",
      "5. Number of Instances: 699 (as of 15 July 1992)\n",
      "\n",
      "6. Number of Attributes: 10 plus the class attribute\n",
      "\n",
      "7. Attribute Information: (class attribute has been moved to last column)\n",
      "\n",
      "       No    Attribute                 Domain\n",
      "       -- -----------------------------------------\n",
      "       1. Sample code number            id, number  \n",
      "       2. Clump Thickness               1 - 10     [\uc138\uade0 \ub450\uaed8]\n",
      "       3. Uniformity of Cell Size       1 - 10     [\uc138\ud3ec\ud06c\uae30\uc758 \uade0\uc77c\uc131]\n",
      "       4. Uniformity of Cell Shape      1 - 10     [\uc138\ud3ec\ubaa8\uc591\uc758 \uade0\uc77c\uc131]\n",
      "       5. Marginal Adhesion             1 - 10     [\ud55c\uacc4 \ubd80\ucc29\ub825]\n",
      "       6. Single Epithelial Cell Size   1 - 10     [\ud558\ub098\uc758 \uc0c1\ud53c\uc138\ucd08 \ud06c\uae30]\n",
      "       7. Bare Nuclei                   1 - 10     [\ub9e8\ud575]\n",
      "       8. Bland Chromatin               1 - 10     [\ub2e8\uc870\ub85c\uc6b4 \uc5fc\uc0c9\uc9c8]\n",
      "       9. Normal Nucleoli               1 - 10     [\ubcf4\ud1b5 \ud575]\n",
      "       10. Mitoses                      1 - 10     [\uc720\uc0ac \ubd84\uc5f4]\n",
      "       11. Class:                        (1 for benign, -1 for malignant)<br><br>\n",
      "\n",
      "8. Missing attribute values: 16\n",
      "\n",
      "   There are 16 instances in Groups 1 to 6 that contain a single missing \n",
      "   (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
      "\n",
      "9. Class distribution:\n",
      " \n",
      "   Benign: 458 (65.5%)\n",
      "   Malignant: 241 (34.5%)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Train \ub2e8\uacc4\n",
      " \ubaa8\ub4e0\uc18d\uc131\uc5d0 \ub300\ud574\uc11c \ubd84\ud560\uc810\uc744 \uad6c\ucd95\ud558\uace0 \uadf8\uc911 \uc5d0\ub7ec\uac12\uc774 \uac00\uc7a5 \uc801\uc740 \ubd84\ud560\uc810\uc744 \ucc3e\ub294\ub2e4."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def adaBoostTrainDS(dataArr,classLabels):\n",
      "    weakClassArr = []\n",
      "    m = shape(dataArr)[0]\n",
      "    D = mat(ones((m,1))/m)   #D: \ud655\ub960 \ubd84\ud3ec\n",
      "    aggClassEst = mat(zeros((m,1)))\n",
      "    for i in range(numIt):\n",
      "        bestStump,error,classEst = buildStump(dataArr,classLabels,D) #\ucd5c\uc801 \ubd84\ud560\uc810, \uc5d0\ub7ec\uac12, \ud074\ub798\uc2a4 \uc608\uce21 \ubca1\ud130\n",
      "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))     #\uc54c\ud30c\uac12 \uacc4\uc0b0\n",
      "        bestStump['alpha'] = alpha       #bestStrump\uc5d0 'dim', 'thresh', 'ineq' \uc778\ub371\uc2a4\uac00 \uc788\uace0, 'alpha'\uc778\ub371\uc2a4\ub97c \ucd94\uac00\ud55c\ub2e4.\n",
      "        weakClassArr.append(bestStump)                  \n",
      "        expon = multiply(-1*alpha*mat(classLabels).T,classEst) \n",
      "        D = multiply(D,exp(expon))                              \n",
      "        D = D/D.sum()\n",
      "        \n",
      "        aggClassEst += alpha*classEst                    #\ubd84\ub958 \uc608\uce21\n",
      "        \n",
      "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))   #\uc608\uce21 \uc5d0\ub7ec \uacc4\uc0b0\n",
      "        errorRate = aggErrors.sum()/m\n",
      "\n",
      "        print \"total error: \",errorRate\n",
      "        if errorRate == 0.0: break\n",
      "    return weakClassArr,aggClassEst\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def buildStump(dataArr,classLabels,D):\n",
      "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
      "    m,n = shape(dataMatrix)\n",
      "    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
      "    minError = inf \n",
      "    for i in range(n):\n",
      "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n",
      "        stepSize = (rangeMax-rangeMin)/numSteps\n",
      "        for j in range(-1,int(numSteps)+1):\n",
      "            for inequal in ['lt', 'gt']: # less than, greater than\n",
      "                threshVal = (rangeMin + float(j) * stepSize)\n",
      "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)\n",
      "                errArr = mat(ones((m,1)))\n",
      "                errArr[predictedVals == labelMat] = 0\n",
      "                weightedError = D.T*errArr  \n",
      "                \n",
      "                if weightedError < minError:\n",
      "                    minError = weightedError\n",
      "                    bestClasEst = predictedVals.copy()\n",
      "                    bestStump['dim'] = i\n",
      "                    bestStump['thresh'] = threshVal\n",
      "                    bestStump['ineq'] = inequal\n",
      "                    \n",
      "    return bestStump,minError,bestClasEst"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from adaboost import *\n",
      "\n",
      "dataArr, labelArr = loadDataSet('cancer_train.txt')\n",
      "classifierArray, aggClassEst = adaBoostTrainDS(dataArr, labelArr, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total error:  0.311983471074\n",
        "total error:  0.311983471074\n",
        "total error:  0.311983471074\n",
        "total error:  0.311983471074\n",
        "total error:  0.309917355372\n",
        "total error:  0.309917355372\n",
        "total error: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.307851239669\n",
        "total error:  0.29958677686\n",
        "total error:  0.297520661157\n",
        "total error:  0.29958677686\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##\ud14c\uc2a4\ud2b8 \ub2e8\uacc4\n",
      " 'threshlneq'\uc640 \uc870\uac74\uc774 \uc77c\uce58\ud558\uba74 -1\uc744 \ubc18\ud658 \ud558\ub294 stumpClassify()\ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec \ud074\ub798\uc2a4 \uc608\uce21\ubca1\ud130\ub97c \uad6c\ud558\uace0\n",
      "  \uc54c\ud30c\uac12\uacfc \uc608\uce21\ubca1\ud130 \uc5f0\uc0b0\uc744 \ud1b5\ud574 \ud074\ub798\uc2a4\ub97c \ubd84\ub958 \ud55c\ub2e4.\n",
      "  0\ubcf4\ub2e4 \uc791\uc73c\uba74 -1\uc744 \ud06c\uba74 1\uc744 \ubc18\ud658\ud55c\ub2e4."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def adaClassify(datToClass,classifierArr):\n",
      "    dataMatrix = mat(datToClass)#do stuff similar to last aggClassEst in adaBoostTrainDS\n",
      "    m = shape(dataMatrix)[0]\n",
      "    aggClassEst = mat(zeros((m,1)))\n",
      "    for i in range(len(classifierArr[0])):\n",
      "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],\\\n",
      "                                 classifierArr[i]['thresh'],\\\n",
      "                                 classifierArr[i]['ineq'])\n",
      "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
      "    print sign(classifierArr[i]['alpha']*classEst) \n",
      "    \n",
      "    return sign(aggClassEst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):\n",
      "    retArray = ones((shape(dataMatrix)[0],1))\n",
      "    if threshIneq == 'lt':\n",
      "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
      "    else:\n",
      "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
      "    return retArray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testArr, testlabel = loadDataSet('cancer_test.txt')\n",
      "\n",
      "prediction = adaClassify(testArr, classifierArray)\n",
      "\n",
      "errArr = mat(ones((len(testArr),1)))\n",
      "err = errArr[prediction != mat(testlabel).T].sum()\n",
      "\n",
      "print 'err =', err/len(testArr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [-1.]\n",
        " [ 1.]\n",
        " [-1.]\n",
        " [ 1.]]\n",
        "191\n",
        "err = 0.455497382199\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plotROC(aggClassEst.T, labelArr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the Area Under the Curve is:  0.67209759937\n"
       ]
      }
     ],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}