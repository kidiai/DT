{
 "metadata": {
  "name": "",
  "signature": "sha256:452802577718ff30f075c60bf121e03408426e8a73169e0f68ba49fc67ec13fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##\uc2e4\ud5d8 \ub370\uc774\ud130\n",
      " 1. Title: Haberman's Survival Data\n",
      "\n",
      "2. Sources:\n",
      "   (a) Donor:   Tjen-Sien Lim (limt@stat.wisc.edu)\n",
      "   (b) Date:    March 4, 1999\n",
      "\n",
      "3. Past Usage:\n",
      "   1. Haberman, S. J. (1976). Generalized Residuals for Log-Linear\n",
      "      Models, Proceedings of the 9th International Biometrics\n",
      "      Conference, Boston, pp. 104-122.\n",
      "   2. Landwehr, J. M., Pregibon, D., and Shoemaker, A. C. (1984),\n",
      "      Graphical Models for Assessing Logistic Regression Models (with\n",
      "      discussion), Journal of the American Statistical Association 79:\n",
      "      61-83.\n",
      "   3. Lo, W.-D. (1993). Logistic Regression Trees, PhD thesis,\n",
      "      Department of Statistics, University of Wisconsin, Madison, WI.\n",
      "\n",
      "4. Relevant Information:\n",
      "   The dataset contains cases from a study that was conducted between\n",
      "   1958 and 1970 at the University of Chicago's Billings Hospital on\n",
      "   the survival of patients who had undergone surgery for breast\n",
      "   cancer.\n",
      "\n",
      "5. Number of Instances: 306\n",
      "\n",
      "6. Number of Attributes: 4 (including the class attribute)\n",
      "\n",
      "7. Attribute Information:\n",
      "   1. Age of patient at time of operation (numerical)                [\uc218\uc220 \ubc1b\uc744\ub54c \ud658\uc790\uc758 \ub098\uc774]\n",
      "   2. Patient's year of operation (year - 1900, numerical)           [\uc218\uc220\ud55c \ub144\ub3c4]\n",
      "   3. Number of positive axillary nodes detected (numerical)         [\uc591\uc131 \uaca8\ub4dc\ub791\uc774 \ub9bc\ud504\uc808 \uac80\ucd9c \uac2f\uc218]\n",
      "   \n",
      "   4. Survival status (class attribute)\n",
      "         1 = the patient survived 5 years or longer\n",
      "         0 = the patient died within 5 year\n",
      "\n",
      "8. Missing Attribute Values: None\n",
      " \n",
      " \n",
      " 306\uac1c\uc758 \ub370\uc774\ud130\uc911 200\uac1c\ub294 Train Set\uc73c\ub85c 106\uac1c\ub294 TestSet\uc73c\ub85c \ud558\uc600\uc74c"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Train \ub2e8\uacc4\n",
      " -\ud14d\uc2a4\ud2b8\uc5d0\uc11c \ud55c\uc904\uc529 \uc77d\ub294\ub2e4.<br>\n",
      " -\uac01 \uc904\uc740 feature1, feature2, feature3, Label\ub85c \ub418\uc5b4 \uc788\ub2e4.<br>\n",
      " -\ubaa8\ub4e0 \uc904\uc744 \uc77d\uc740 \ud6c4, Gradient Descent\ubc29\ubc95\uc744 \uc774\uc6a9\ud574\uc11c \ubc18\ubcf5\uc744 \ud1b5\ud574 weight\uac12\uc744 \uacc4\uc0b0\ud55c\ub2e4.<br>\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def TrainM(fp, it):\n",
      "    frTrain = open(fp, 'r'); \n",
      "    idx=0\n",
      "    trainingSet = []; trainingLabels = []\n",
      "    for line in frTrain.readlines():\n",
      "        currLine = line.strip().split('\\t')\n",
      "        \n",
      "        lineArr =[]\n",
      "        for i in range(3):\n",
      "            lineArr.append(float(currLine[i]))\n",
      "        trainingSet.append(lineArr)\n",
      "        trainingLabels.append(float(currLine[3]))\n",
      "        idx = idx+1\n",
      "    print 'for\ubb38 \ub05d'\n",
      "    trainWeights = stocGradDescent(array(trainingSet), trainingLabels, it)\n",
      "    return trainWeights\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\ucc98\uc74c\uc5d0 weight\uac12\uc744 1\ub85c \ucd08\uae30\ud654 \uc2dc\ucf1c\uc8fc\uace0, step-size\ub294 0.0001\ub85c \ud558\uace0 \ubc18\ubcf5 \uc218\ud589\uc2dc\ucf1c \uc900\ub2e4.\n",
      "\n",
      "   ###${ w }_{ n+1 }={ w }_{ n }\u2212\u03b3\u2207F({ x }_{ n })$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stocGradDescent(dataMatrix, classLabels, numIter):\n",
      "    m,n = shape(dataMatrix)\n",
      "    weights = ones(n)\n",
      "    for k in range(numIter):\n",
      "        for i in range(m):\n",
      "            alpha =0.0001            \n",
      "            h=sigmoid(sum(dataMatrix[i] * weights)) \n",
      "            error = (classLabels[i] - h)\n",
      "            weights = weights - alpha * dataMatrix[i] * error\n",
      "        print '{0} iter weight = {1}\\n'.format(k+1, weights)\n",
      "    return weights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logRegres as reg\n",
      "\n",
      "weight = reg.TrainM('oper_train.txt', 150, 1)\n",
      "print 'weight = {0}'.format(weight)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 ['47', '63', '6', '1']\n",
        "2 ['47', '66', '0', '1']\n",
        "3 ['47', '67', '0', '1']\n",
        "4 ['47', '58', '3', '1']\n",
        "5 ['47', '60', '4', '1']\n",
        "6 ['47', '68', '4', '1']\n",
        "7 ['47', '66', '12', '1']\n",
        "8 ['48', '58', '11', '0']\n",
        "9 ['48', '58', '11', '0']\n",
        "10 ['48', '67', '7', '0']\n",
        "11 ['48', '61', '8', '1']\n",
        "12 ['48', '62', '2', '1']\n",
        "13 ['48', '64', '0', '1']\n",
        "14 ['48', '66', '0', '1']\n",
        "15 ['49', '63', '0', '0']\n",
        "16 ['49', '64', '10', '0']\n",
        "17 ['49', '61', '1', '1']\n",
        "18 ['49', '62', '0', '1']\n",
        "19 ['49', '66', '0', '1']\n",
        "20 ['49', '60', '1', '1']\n",
        "21 ['49', '62', '1', '1']\n",
        "22 ['49', '63', '3', '1']\n",
        "23 ['49', '61', '0', '1']\n",
        "24 ['49', '67', '1', '1']\n",
        "25 ['50', '63', '13', '0']\n",
        "26 ['50', '64', '0', '0']\n",
        "27 ['50', '59', '0', '1']\n",
        "28 ['50', '61', '6', '1']\n",
        "29 ['50', '61', '0', '1']\n",
        "30 ['50', '63', '1', '1']\n",
        "31 ['50', '58', '1', '1']\n",
        "32 ['50', '59', '2', '1']\n",
        "33 ['50', '61', '0', '1']\n",
        "34 ['50', '64', '0', '1']\n",
        "35 ['50', '65', '4', '1']\n",
        "36 ['50', '66', '1', '1']\n",
        "37 ['51', '59', '13', '0']\n",
        "38 ['51', '59', '3', '0']\n",
        "39 ['51', '64', '7', '1']\n",
        "40 ['51', '59', '1', '1']\n",
        "41 ['51', '65', '0', '1']\n",
        "42 ['51', '66', '1', '1']\n",
        "43 ['52', '69', '3', '0']\n",
        "44 ['52', '59', '2', '0']\n",
        "45 ['52', '62', '3', '0']\n",
        "46 ['52', '66', '4', '0']\n",
        "47 ['52', '61', '0', '1']\n",
        "48 ['52', '63', '4', '1']\n",
        "49 ['52', '69', '0', '1']\n",
        "50 ['52', '60', '4', '1']\n",
        "51 ['52', '60', '5', '1']\n",
        "52 ['52', '62', '0', '1']\n",
        "53 ['52', '62', '1', '1']\n",
        "54 ['52', '64', '0', '1']\n",
        "55 ['52', '65', '0', '1']\n",
        "56 ['52', '68', '0', '1']\n",
        "57 ['53', '58', '4', '0']\n",
        "58 ['53', '65', '1', '0']\n",
        "59 ['53', '59', '3', '0']\n",
        "60 ['53', '60', '9', '0']\n",
        "61 ['53', '63', '24', '0']\n",
        "62 ['53', '65', '12', '0']\n",
        "63 ['53', '58', '1', '1']\n",
        "64 ['53', '60', '1', '1']\n",
        "65 ['53', '60', '2', '1']\n",
        "66 ['53', '61', '1', '1']\n",
        "67 ['53', '63', '0', '1']\n",
        "68 ['54', '60', '11', '0']\n",
        "69 ['54', '65', '23', '0']\n",
        "70 ['54', '65', '5', '0']\n",
        "71 ['54', '68', '7', '0']\n",
        "72 ['54', '59', '7', '1']\n",
        "73 ['54', '60', '3', '1']\n",
        "74 ['54', '66', '0', '1']\n",
        "75 ['54', '67', '46', '1']\n",
        "76 ['54', '62', '0', '1']\n",
        "77 ['54', '69', '7', '1']\n",
        "78 ['54', '63', '19', '1']\n",
        "79 ['54', '58', '1', '1']\n",
        "80 ['54', '62', '0', '1']\n",
        "81 ['55', '63', '6', '0']\n",
        "82 ['55', '68', '15', '0']\n",
        "83 ['55', '58', '1', '1']\n",
        "84 ['55', '58', '0', '1']\n",
        "85 ['55', '58', '1', '1']\n",
        "86 ['55', '66', '18', '1']\n",
        "87 ['55', '66', '0', '1']\n",
        "88 ['55', '69', '3', '1']\n",
        "89 ['55', '69', '22', '1']\n",
        "90 ['55', '67', '1', '1']\n",
        "91 ['56', '65', '9', '0']\n",
        "92 ['56', '66', '3', '0']\n",
        "93 ['56', '60', '0', '1']\n",
        "94 ['56', '66', '2', '1']\n",
        "95 ['56', '66', '1', '1']\n",
        "96 ['56', '67', '0', '1']\n",
        "97 ['56', '60', '0', '1']\n",
        "98 ['57', '61', '5', '0']\n",
        "99 ['57', '62', '14', '0']\n",
        "100 ['57', '64', '1', '0']\n",
        "101 ['57', '64', '9', '1']\n",
        "102 ['57', '69', '0', '1']\n",
        "103 ['57', '61', '0', '1']\n",
        "104 ['57', '62', '0', '1']\n",
        "105 ['57', '63', '0', '1']\n",
        "106 ['57', '64', '0', '1']\n",
        "107 ['57', '64', '0', '1']\n",
        "108 ['57', '67', '0', '1']\n",
        "109 ['58', '59', '0', '1']\n",
        "110 ['58', '60', '3', '1']\n",
        "111 ['58', '61', '1', '1']\n",
        "112 ['58', '67', '0', '1']\n",
        "113 ['58', '58', '0', '1']\n",
        "114 ['58', '58', '3', '1']\n",
        "115 ['58', '61', '2', '1']\n",
        "116 ['59', '62', '35', '0']\n",
        "117 ['59', '60', '0', '1']\n",
        "118 ['59', '63', '0', '1']\n",
        "119 ['59', '64', '1', '1']\n",
        "120 ['59', '64', '4', '1']\n",
        "121 ['59', '64', '0', '1']\n",
        "122 ['59', '64', '7', '1']\n",
        "123 ['59', '67', '3', '1']\n",
        "124 ['60', '59', '17', '0']\n",
        "125 ['60', '65', '0', '0']\n",
        "126 ['60', '61', '1', '1']\n",
        "127 ['60', '67', '2', '1']\n",
        "128 ['60', '61', '25', '1']\n",
        "129 ['60', '64', '0', '1']\n",
        "130 ['61', '62', '5', '0']\n",
        "131 ['61', '65', '0', '0']\n",
        "132 ['61', '68', '1', '0']\n",
        "133 ['61', '59', '0', '1']\n",
        "134 ['61', '59', '0', '1']\n",
        "135 ['61', '64', '0', '1']\n",
        "136 ['61', '65', '8', '1']\n",
        "137 ['61', '68', '0', '1']\n",
        "138 ['61', '59', '0', '1']\n",
        "139 ['62', '59', '13', '0']\n",
        "140 ['62', '58', '0', '0']\n",
        "141 ['62', '65', '19', '0']\n",
        "142 ['62', '62', '6', '1']\n",
        "143 ['62', '66', '0', '1']\n",
        "144 ['62', '66', '0', '1']\n",
        "145 ['62', '58', '0', '1']\n",
        "146 ['63', '60', '1', '0']\n",
        "147 ['63', '61', '0', '1']\n",
        "148 ['63', '62', '0', '1']\n",
        "149 ['63', '63', '0', '1']\n",
        "150 ['63', '63', '0', '1']\n",
        "151 ['63', '66', '0', '1']\n",
        "152 ['63', '61', '9', '1']\n",
        "153 ['63', '61', '28', '1']\n",
        "154 ['64', '58', '0', '1']\n",
        "155 ['64', '65', '22', '1']\n",
        "156 ['64', '66', '0', '1']\n",
        "157 ['64', '61', '0', '1']\n",
        "158 ['64', '68', '0', '1']\n",
        "159 ['65', '58', '0', '0']\n",
        "160 ['65', '61', '2', '0']\n",
        "161 ['65', '62', '22', '0']\n",
        "162 ['65', '66', '15', '0']\n",
        "163 ['65', '58', '0', '1']\n",
        "164 ['65', '64', '0', '1']\n",
        "165 ['65', '67', '0', '1']\n",
        "166 ['65', '59', '2', '1']\n",
        "167 ['65', '64', '0', '1']\n",
        "168 ['65', '67', '1', '1']\n",
        "169 ['66', '58', '0', '0']\n",
        "170 ['66', '61', '13', '0']\n",
        "171 ['66', '58', '0', '1']\n",
        "172 ['66', '58', '1', '1']\n",
        "173 ['66', '68', '0', '1']\n",
        "174 ['67', '64', '8', '0']\n",
        "175 ['67', '63', '1', '0']\n",
        "176 ['67', '66', '0', '1']\n",
        "177 ['67', '66', '0', '1']\n",
        "178 ['67', '61', '0', '1']\n",
        "179 ['67', '65', '0', '1']\n",
        "180 ['68', '67', '0', '1']\n",
        "181 ['68', '68', '0', '1']\n",
        "182 ['69', '67', '8', '0']\n",
        "183 ['69', '60', '0', '1']\n",
        "184 ['69', '65', '0', '1']\n",
        "185 ['69', '66', '0', '1']\n",
        "186 ['70', '58', '0', '0']\n",
        "187 ['70', '58', '4', '0']\n",
        "188 ['70', '66', '14', '1']\n",
        "189 ['70', '67', '0', '1']\n",
        "190 ['70', '68', '0', '1']\n",
        "191 ['70', '59', '8', '1']\n",
        "192 ['70', '63', '0', '1']\n",
        "193 ['71', '68', '2', '1']\n",
        "194 ['72', '63', '0', '0']\n",
        "195 ['72', '58', '0', '1']\n",
        "196 ['72', '64', '0', '1']\n",
        "197 ['72', '67', '3', '1']\n",
        "198 ['73', '62', '0', '1']\n",
        "199 ['73', '68', '0', '1']\n",
        "200 ['74', '65', '3', '0']\n",
        "201 ['74', '63', '0', '1']\n",
        "202 ['75', '62', '1', '1']\n",
        "203 ['76', '67', '0', '1']\n",
        "204 ['77', '65', '3', '1']\n",
        "205 ['78', '65', '1', '0']\n",
        "206 ['83', '58', '2', '0']\n",
        "\n",
        "for\ubb38 \ub05d\n",
        "\n",
        "1 iter weight = [ 1.3232  1.3438  1.0402]\n",
        "\n",
        "2 iter weight = [ 1.6464  1.6876  1.0804]\n",
        "\n",
        "3 iter weight = [ 1.9696  2.0314  1.1206]\n",
        "\n",
        "4 iter weight = [ 2.2928  2.3752  1.1608]\n",
        "\n",
        "5 iter weight = [ 2.616  2.719  1.201]\n",
        "\n",
        "6 iter weight = [ 2.9392  3.0628  1.2412]\n",
        "\n",
        "7 iter weight = [ 3.2624  3.4066  1.2814]\n",
        "\n",
        "8 iter weight = [ 3.5856  3.7504  1.3216]\n",
        "\n",
        "9 iter weight = [ 3.9088  4.0942  1.3618]\n",
        "\n",
        "10 iter weight = [ 4.232  4.438  1.402]\n",
        "\n",
        "11 iter weight = [ 4.5552  4.7818  1.4422]\n",
        "\n",
        "12 iter weight = [ 4.8784  5.1256  1.4824]\n",
        "\n",
        "13 iter weight = [ 5.2016  5.4694  1.5226]\n",
        "\n",
        "14 iter weight = [ 5.5248  5.8132  1.5628]\n",
        "\n",
        "15 iter weight = [ 5.848  6.157  1.603]\n",
        "\n",
        "16 iter weight = [ 6.1712  6.5008  1.6432]\n",
        "\n",
        "17 iter weight = [ 6.4944  6.8446  1.6834]\n",
        "\n",
        "18 iter weight = [ 6.8176  7.1884  1.7236]\n",
        "\n",
        "19 iter weight = [ 7.1408  7.5322  1.7638]\n",
        "\n",
        "20 iter weight = [ 7.464  7.876  1.804]\n",
        "\n",
        "21 iter weight = [ 7.7872  8.2198  1.8442]\n",
        "\n",
        "22 iter weight = [ 8.1104  8.5636  1.8844]\n",
        "\n",
        "23 iter weight = [ 8.4336  8.9074  1.9246]\n",
        "\n",
        "24 iter weight = [ 8.7568  9.2512  1.9648]\n",
        "\n",
        "25 iter weight = [ 9.08   9.595  2.005]\n",
        "\n",
        "26 iter weight = [ 9.4032  9.9388  2.0452]\n",
        "\n",
        "27 iter weight = [  9.7264  10.2826   2.0854]\n",
        "\n",
        "28 iter weight = [ 10.0496  10.6264   2.1256]\n",
        "\n",
        "29 iter weight = [ 10.3728  10.9702   2.1658]\n",
        "\n",
        "30 iter weight = [ 10.696  11.314   2.206]\n",
        "\n",
        "31 iter weight = [ 11.0192  11.6578   2.2462]\n",
        "\n",
        "32 iter weight = [ 11.3424  12.0016   2.2864]\n",
        "\n",
        "33 iter weight = [ 11.6656  12.3454   2.3266]\n",
        "\n",
        "34 iter weight = [ 11.9888  12.6892   2.3668]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35 iter weight = [ 12.312  13.033   2.407]\n",
        "\n",
        "36 iter weight = [ 12.6352  13.3768   2.4472]\n",
        "\n",
        "37 iter weight = [ 12.9584  13.7206   2.4874]\n",
        "\n",
        "38 iter weight = [ 13.2816  14.0644   2.5276]\n",
        "\n",
        "39 iter weight = [ 13.6048  14.4082   2.5678]\n",
        "\n",
        "40 iter weight = [ 13.928  14.752   2.608]\n",
        "\n",
        "41 iter weight = [ 14.2512  15.0958   2.6482]\n",
        "\n",
        "42 iter weight = [ 14.5744  15.4396   2.6884]\n",
        "\n",
        "43 iter weight = [ 14.8976  15.7834   2.7286]\n",
        "\n",
        "44 iter weight = [ 15.2208  16.1272   2.7688]\n",
        "\n",
        "45 iter weight = [ 15.544  16.471   2.809]\n",
        "\n",
        "46 iter weight = [ 15.8672  16.8148   2.8492]\n",
        "\n",
        "47 iter weight = [ 16.1904  17.1586   2.8894]\n",
        "\n",
        "48 iter weight = [ 16.5136  17.5024   2.9296]\n",
        "\n",
        "49 iter weight = [ 16.8368  17.8462   2.9698]\n",
        "\n",
        "50 iter weight = [ 17.16  18.19   3.01]\n",
        "\n",
        "51 iter weight = [ 17.4832  18.5338   3.0502]\n",
        "\n",
        "52 iter weight = [ 17.8064  18.8776   3.0904]\n",
        "\n",
        "53 iter weight = [ 18.1296  19.2214   3.1306]\n",
        "\n",
        "54 iter weight = [ 18.4528  19.5652   3.1708]\n",
        "\n",
        "55 iter weight = [ 18.776  19.909   3.211]\n",
        "\n",
        "56 iter weight = [ 19.0992  20.2528   3.2512]\n",
        "\n",
        "57 iter weight = [ 19.4224  20.5966   3.2914]\n",
        "\n",
        "58 iter weight = [ 19.7456  20.9404   3.3316]\n",
        "\n",
        "59 iter weight = [ 20.0688  21.2842   3.3718]\n",
        "\n",
        "60 iter weight = [ 20.392  21.628   3.412]\n",
        "\n",
        "61 iter weight = [ 20.7152  21.9718   3.4522]\n",
        "\n",
        "62 iter weight = [ 21.0384  22.3156   3.4924]\n",
        "\n",
        "63 iter weight = [ 21.3616  22.6594   3.5326]\n",
        "\n",
        "64 iter weight = [ 21.6848  23.0032   3.5728]\n",
        "\n",
        "65 iter weight = [ 22.008  23.347   3.613]\n",
        "\n",
        "66 iter weight = [ 22.3312  23.6908   3.6532]\n",
        "\n",
        "67 iter weight = [ 22.6544  24.0346   3.6934]\n",
        "\n",
        "68 iter weight = [ 22.9776  24.3784   3.7336]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "69 iter weight = [ 23.3008  24.7222   3.7738]\n",
        "\n",
        "70 iter weight = [ 23.624  25.066   3.814]\n",
        "\n",
        "71 iter weight = [ 23.9472  25.4098   3.8542]\n",
        "\n",
        "72 iter weight = [ 24.2704  25.7536   3.8944]\n",
        "\n",
        "73 iter weight = [ 24.5936  26.0974   3.9346]\n",
        "\n",
        "74 iter weight = [ 24.9168  26.4412   3.9748]\n",
        "\n",
        "75 iter weight = [ 25.24   26.785   4.015]\n",
        "\n",
        "76 iter weight = [ 25.5632  27.1288   4.0552]\n",
        "\n",
        "77 iter weight = [ 25.8864  27.4726   4.0954]\n",
        "\n",
        "78 iter weight = [ 26.2096  27.8164   4.1356]\n",
        "\n",
        "79 iter weight = [ 26.5328  28.1602   4.1758]\n",
        "\n",
        "80 iter weight = [ 26.856  28.504   4.216]\n",
        "\n",
        "81 iter weight = [ 27.1792  28.8478   4.2562]\n",
        "\n",
        "82 iter weight = [ 27.5024  29.1916   4.2964]\n",
        "\n",
        "83 iter weight = [ 27.8256  29.5354   4.3366]\n",
        "\n",
        "84 iter weight = [ 28.1488  29.8792   4.3768]\n",
        "\n",
        "85 iter weight = [ 28.472  30.223   4.417]\n",
        "\n",
        "86 iter weight = [ 28.7952  30.5668   4.4572]\n",
        "\n",
        "87 iter weight = [ 29.1184  30.9106   4.4974]\n",
        "\n",
        "88 iter weight = [ 29.4416  31.2544   4.5376]\n",
        "\n",
        "89 iter weight = [ 29.7648  31.5982   4.5778]\n",
        "\n",
        "90 iter weight = [ 30.088  31.942   4.618]\n",
        "\n",
        "91 iter weight = [ 30.4112  32.2858   4.6582]\n",
        "\n",
        "92 iter weight = [ 30.7344  32.6296   4.6984]\n",
        "\n",
        "93 iter weight = [ 31.0576  32.9734   4.7386]\n",
        "\n",
        "94 iter weight = [ 31.3808  33.3172   4.7788]\n",
        "\n",
        "95 iter weight = [ 31.704  33.661   4.819]\n",
        "\n",
        "96 iter weight = [ 32.0272  34.0048   4.8592]\n",
        "\n",
        "97 iter weight = [ 32.3504  34.3486   4.8994]\n",
        "\n",
        "98 iter weight = [ 32.6736  34.6924   4.9396]\n",
        "\n",
        "99 iter weight = [ 32.9968  35.0362   4.9798]\n",
        "\n",
        "100 iter weight = [ 33.32  35.38   5.02]\n",
        "\n",
        "101 iter weight = [ 33.6432  35.7238   5.0602]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102 iter weight = [ 33.9664  36.0676   5.1004]\n",
        "\n",
        "103 iter weight = [ 34.2896  36.4114   5.1406]\n",
        "\n",
        "104 iter weight = [ 34.6128  36.7552   5.1808]\n",
        "\n",
        "105 iter weight = [ 34.936  37.099   5.221]\n",
        "\n",
        "106 iter weight = [ 35.2592  37.4428   5.2612]\n",
        "\n",
        "107 iter weight = [ 35.5824  37.7866   5.3014]\n",
        "\n",
        "108 iter weight = [ 35.9056  38.1304   5.3416]\n",
        "\n",
        "109 iter weight = [ 36.2288  38.4742   5.3818]\n",
        "\n",
        "110 iter weight = [ 36.552  38.818   5.422]\n",
        "\n",
        "111 iter weight = [ 36.8752  39.1618   5.4622]\n",
        "\n",
        "112 iter weight = [ 37.1984  39.5056   5.5024]\n",
        "\n",
        "113 iter weight = [ 37.5216  39.8494   5.5426]\n",
        "\n",
        "114 iter weight = [ 37.8448  40.1932   5.5828]\n",
        "\n",
        "115 iter weight = [ 38.168  40.537   5.623]\n",
        "\n",
        "116 iter weight = [ 38.4912  40.8808   5.6632]\n",
        "\n",
        "117 iter weight = [ 38.8144  41.2246   5.7034]\n",
        "\n",
        "118 iter weight = [ 39.1376  41.5684   5.7436]\n",
        "\n",
        "119 iter weight = [ 39.4608  41.9122   5.7838]\n",
        "\n",
        "120 iter weight = [ 39.784  42.256   5.824]\n",
        "\n",
        "121 iter weight = [ 40.1072  42.5998   5.8642]\n",
        "\n",
        "122 iter weight = [ 40.4304  42.9436   5.9044]\n",
        "\n",
        "123 iter weight = [ 40.7536  43.2874   5.9446]\n",
        "\n",
        "124 iter weight = [ 41.0768  43.6312   5.9848]\n",
        "\n",
        "125 iter weight = [ 41.4    43.975   6.025]\n",
        "\n",
        "126 iter weight = [ 41.7232  44.3188   6.0652]\n",
        "\n",
        "127 iter weight = [ 42.0464  44.6626   6.1054]\n",
        "\n",
        "128 iter weight = [ 42.3696  45.0064   6.1456]\n",
        "\n",
        "129 iter weight = [ 42.6928  45.3502   6.1858]\n",
        "\n",
        "130 iter weight = [ 43.016  45.694   6.226]\n",
        "\n",
        "131 iter weight = [ 43.3392  46.0378   6.2662]\n",
        "\n",
        "132 iter weight = [ 43.6624  46.3816   6.3064]\n",
        "\n",
        "133 iter weight = [ 43.9856  46.7254   6.3466]\n",
        "\n",
        "134 iter weight = [ 44.3088  47.0692   6.3868]\n",
        "\n",
        "135 iter weight = [ 44.632  47.413   6.427]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "136 iter weight = [ 44.9552  47.7568   6.4672]\n",
        "\n",
        "137 iter weight = [ 45.2784  48.1006   6.5074]\n",
        "\n",
        "138 iter weight = [ 45.6016  48.4444   6.5476]\n",
        "\n",
        "139 iter weight = [ 45.9248  48.7882   6.5878]\n",
        "\n",
        "140 iter weight = [ 46.248  49.132   6.628]\n",
        "\n",
        "141 iter weight = [ 46.5712  49.4758   6.6682]\n",
        "\n",
        "142 iter weight = [ 46.8944  49.8196   6.7084]\n",
        "\n",
        "143 iter weight = [ 47.2176  50.1634   6.7486]\n",
        "\n",
        "144 iter weight = [ 47.5408  50.5072   6.7888]\n",
        "\n",
        "145 iter weight = [ 47.864  50.851   6.829]\n",
        "\n",
        "146 iter weight = [ 48.1872  51.1948   6.8692]\n",
        "\n",
        "147 iter weight = [ 48.5104  51.5386   6.9094]\n",
        "\n",
        "148 iter weight = [ 48.8336  51.8824   6.9496]\n",
        "\n",
        "149 iter weight = [ 49.1568  52.2262   6.9898]\n",
        "\n",
        "150 iter weight = [ 49.48  52.57   7.03]\n",
        "\n",
        "weight = [ 49.48  52.57   7.03]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Test \ub2e8\uacc4\n",
      " -\ud14d\uc2a4\ud2b8\uc5d0\uc11c \ud55c\uc904\uc529 \uc77d\ub294\ub2e4.<br>\n",
      " -\uac01 \uc904\uc740 feature1, feature2, feature3, Label\ub85c \ub418\uc5b4 \uc788\ub2e4.<br>\n",
      " -\ubaa8\ub4e0 \uc904\uc744 \uc77d\uc740 \ud6c4, sigmoid\ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec 0, 1\ub85c \ubd84\ub958\ub97c \ud55c\ud6c4, label\uacfc \ube44\uad50\ud55c\ub2e4<br>\n",
      " -\ubc18\ud658\uac12\uc73c\ub85c \uc624\ub958\uc728\ub97c \ubc18\ud658\ud574\uc900\ub2e4."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def TestM(fp, trainWeights):\n",
      "    frTest = open(fp, 'r')\n",
      "    errorCount = 0; numTestVec = 0.0\n",
      "    for line in frTest.readlines():\n",
      "        numTestVec += 1.0\n",
      "        currLine = line.strip().split('\\t')\n",
      "        lineArr =[]\n",
      "        for i in range(3):\n",
      "            lineArr.append(float(currLine[i]))\n",
      "        if int(classifyVector(array(lineArr), trainWeights))!= int(currLine[3]):\n",
      "            errorCount += 1\n",
      "    errorRate = (float(errorCount)/numTestVec)\n",
      "    print \"the error rate of this test is: %f\" % errorRate\n",
      "    return errorRate\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###sigmoid \ud568\uc218\uc5d0 \uc785\ub825\uac12\uacfc train\ub2e8\uacc4\uc5d0\uc11c \uacc4\uc0b0\ud55c weights\uc744 \ub123\uc5b4\uc11c \ubd84\ub958\ub97c \uc218\ud589\ud55c\ub2e4.<br>\n",
      "0.5\ubcf4\ub2e4 \ud06c\ub2e4 1\ub85c, \uc791\uac70\ub098 \uac19\uc73c\uba74 0\uc73c\ub85c \ubd84\ub958 \ud55c\ub2e4. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "x=np.arange(-10.,10.,0.2)\n",
      "sig=1.0/(1+np.exp(-x))\n",
      "plt.plot(x,sig)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classifyVector(inX, weights):\n",
      "    prob = sigmoid(sum(inX*weights))\n",
      "    if prob > 0.5: return 1.0\n",
      "    else: return 0.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errRate = reg.TestM('oper_test.txt', weight)\n",
      "reg.plot3D('oper_test.txt', weight)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the error rate of this test is: 0.260000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Anaconda\\lib\\site-packages\\mpl_toolkits\\mplot3d\\axes3d.py:1094: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
        "  if self.button_pressed in self._rotate_btn:\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}